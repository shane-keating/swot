{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGzCgu107Zz8O6oHa0KD5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shane-keating/swot/blob/master/AUSWOT_tutorial_AMOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUSWOT tutorial: A SWOT data primer\n",
        "\n",
        "This tutorial will introduce you to some sample SWOT data and show you how to download data and perform some basic data wrangling tasks. \n",
        "\n",
        "## Learning outcomes\n",
        "- Introduce SWOT sample data products\n",
        "- Introduce and register for the NASA Earthdata server\n",
        "- Show you how to find and visualize SWOT data sets on the Earthdata\n",
        "- Download SWOT KaRIn (2D swath) and nadir (along-track) altimetry data directly to Google Colab\n",
        "- Explore and merge Xarray datasets\n",
        "- Swath and nadir plotting\n",
        "\n",
        "This tutorial has been shamelessly adapted from tutorials developed by NASA PO.DAAC. All kudos to them. "
      ],
      "metadata": {
        "id": "F5l9prJtHsMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "We will run this tutorial in [Google Colaboratory](colab.research.google.com). Google Colab is a web-based computational environment in which you can read, write, and execute interactive *notebooks* like the one you are reading. The python code runs on a virtual machine in the cloud, so you don't need to install python on your local machine. \n",
        "\n",
        "Before you begin the lab, you might like to [sign up](https://accounts.google.com/signup) for a free Google account. If you do not wish to sign up for a Google account, that's fine: you will still be able to run the lab in \"sandbox\" mode. You just won't be able save any changes you make. \n",
        "\n",
        "### Colaboratory and Google Drive\n",
        "\n",
        "If you have a Google account, you can mount your Google drive within the Colab environment. This is not required to run the lab. But if you would like to save output you can do so by navigating to `drive/'My Drive'` \n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls drive/'My Drive'\n",
        "```\n",
        "\n",
        "If you would like, you can save a copy of this notebook to your local machine or to your Google drive so you can save your output or see any notes you made within the notebook. "
      ],
      "metadata": {
        "id": "Kmj-0Sv2Nu_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial steps\n",
        "\n",
        "In this tutorial, we will explore three different SWOT datasets: \n",
        "\n",
        "- SWOT Sample Data Products v1.2: A sample dataset of simulated SWOT products available for direct download: https://podaac.jpl.nasa.gov/SWOT?tab=datasets&sections=about%2Bdata\n",
        "\n",
        "- SWOT simulated Level 2 KaRIn SSH v1 dataset: Simulated KaRIn (2D swath) SSH measurements available on NASA Earthdata. https://podaac.jpl.nasa.gov/announcements/2022-01-31-Release-simulated-SWOT-SSH-version1-datasets\n",
        "\n",
        "- SWOT simulated Nadir altimetry dataset: Simulated nadir (along-track) SSH measurements available on NASA Earthdata.  https://podaac.jpl.nasa.gov/announcements/2022-01-31-Release-simulated-SWOT-SSH-version1-datasets\n",
        "\n",
        "\n",
        "The SSH data in these datasets is derived from the GLORYS ocean model and the SWOT simulator, which reproduces the sampling pattern and errors of the future SWOT mission. The second two datasets replicate the data format of the real SWOT data when it is released on Earthdata. In this tutorial, we will focus on the Science orbit (21-day repeat). At the above links you can also find simualted data for the Cal/Val orbit (1-day repeat). \n",
        "\n",
        "If you have not already done so, you should first create a (free) Earthdata login: https://www.earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/earthdata-login"
      ],
      "metadata": {
        "id": "jNl0HH5uI9xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install modules and libraries"
      ],
      "metadata": {
        "id": "bADAhD4aTLZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by installing a couple of modules we will need: `s3fs` and `cartopy`"
      ],
      "metadata": {
        "id": "bKadLHV08ruY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install s3fs\n",
        "! pip install cartopy\n",
        "! pip uninstall shapely -y\n",
        "! pip install shapely --no-binary shapely"
      ],
      "metadata": {
        "id": "COn4_7dKxcSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's import libraries."
      ],
      "metadata": {
        "id": "zOy0yTp080D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import s3fs\n",
        "import requests\n",
        "import xarray as xr\n",
        "import pylab as plt\n",
        "from netrc import netrc\n",
        "from urllib import request\n",
        "from platform import system\n",
        "from getpass import getpass\n",
        "from http.cookiejar import CookieJar\n",
        "from os.path import expanduser, join\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "from matplotlib import pyplot as plt\n",
        "from os import path\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "d_vjHJj1xd5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the SWOT Sample Data Set\n",
        "\n",
        "We will begin by downloading the SWOT Sample Data Set directly into Google Colab. The dataset is fairly large (~2.4 Gb) so it may take a few minutes. If downloading a dataset this large is prohibitive, you can skip this section and move to the Earthdata datasets below. \n",
        "\n",
        "Note that you will be downloading the dataset to your Google Colab virtual machine, *not* to your local machine. You can also download or upload data to and from your local machine using the folder icon in the toolbar to the left. \n",
        "\n",
        "If you have a Google Drive, you can use the instructions described above to connect it to your Google Colab virtual machine and save the data set there (as well as this notebook). \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0donn3EqM3Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://podaac.jpl.nasa.gov/sites/default/files/content/PODAAC_Documentation/swot_mission_docs/SWOT_sample_data_products_v1.2/L2_LR_SSH.tar.gz"
      ],
      "metadata": {
        "id": "Ahl3QrknOS5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you click on the folder icon to the left you will see a zipped directory called `L2_LR_SSH.tar.gz` sitting in your Google virtual machine. We can unzip this folder using the following command: "
      ],
      "metadata": {
        "id": "mFLO6uOVOxez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf L2_LR_SSH.tar.gz"
      ],
      "metadata": {
        "id": "yWlq7pmRPAj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will now see a new directory called `L2_LR_SSH` containing a large number of netcdf files (`.nc`). These contain a variety of simulated SWOT data products labelled as \"Basic\", \"Wind and Wave\", \"Expert\" and \"Unsmoothed\". We will be using the \"Basic\" data products. A full description of the dataset can be found here: https://podaac-tools.jpl.nasa.gov/drive/files/misc/web/misc/swot_mission_docs/pdd/D-56407_SWOT_Product_Description_L2_LR_SSH_20220902_RevA.pdf\n",
        "\n",
        "Now let's read in one of the files using `xarray` and explore the data variables and attributes contained in the dataset. "
      ],
      "metadata": {
        "id": "RzZl7umEQTfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds0 = xr.open_dataset('L2_LR_SSH/SWOT_L2_LR_SSH_Basic_001_008_20160901T060008_20160901T065134_DG10_01.nc')\n",
        "ds0"
      ],
      "metadata": {
        "id": "aIAuLXBSTm1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the data\n",
        "\n",
        "The pass we have imported contains the Bass Strait and Southern Ocean regions. Let's visualize some of the KaRIn data in these region using `cartopy`. \n",
        "\n",
        "Adapt this code to visualize other variables or regions, or try importing another file. "
      ],
      "metadata": {
        "id": "gYtT4BzpUzjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lolabox = [140, 160, -60, -40  ] # Southern Ocean\n",
        "#lolabox = [143, 147, -42, -38] # Bass strait region\n",
        "\n",
        "plt.figure(figsize=(21, 12))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent(lolabox)\n",
        "ds0.ssha_karin.plot.pcolormesh(\n",
        " ax=ax, transform=ccrs.PlateCarree(), x=\"longitude\", y=\"latitude\", add_colorbar=True\n",
        ")\n",
        "ax.coastlines()"
      ],
      "metadata": {
        "id": "og4ikCh7U124"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data discovery on Earthdata\n",
        "\n",
        "The data we have examined so far is a small sample set that you can use to play around with SWOT data. However, real SWOT data will not be available in this form. In the next part of the tutorial, we will introduce [Earthdata](https://www.earthdata.nasa.gov/), which is the gateway to NASA Earth Science Data, including the Physical Oceanography Distributed Active Archive Centre, or [PO.DAAC](https://podaac.jpl.nasa.gov/). \n",
        "\n",
        "Earthdata has a number of datasets and products that replicate future SWOT data as well as high-resolution numerical model output for pre-launch and post-launch calibration and validation activities. \n",
        "\n",
        "Let's start by exploring some tools for data discovery on Earthdata. You will need an [Earthdata login](https://www.earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/earthdata-login) to do this part of the tutorial. \n",
        "\n",
        "- Method 1: [Earthdata Search](https://search.earthdata.nasa.gov/search)\n",
        "- Method 2: [HiTIDE interactive data extraction](https://hitide.podaac.earthdatacloud.nasa.gov/)\n"
      ],
      "metadata": {
        "id": "YYqYICnI84b_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing data from PO.DAAC and Earthdata\n",
        "\n",
        "Now let's see how you can import data from Earthdata directly into Colab. First you need to connect with Earthdata and provide your Earthdata credentials (username and password). "
      ],
      "metadata": {
        "id": "ZJNuZTCljgVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_earthdata_login_auth(endpoint: str='urs.earthdata.nasa.gov'):\n",
        "    netrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n",
        "    try:\n",
        "        username, _, password = netrc(file=join(expanduser('~'), netrc_name)).authenticators(endpoint)\n",
        "    except (FileNotFoundError, TypeError):\n",
        "        print('Please provide your Earthdata Login credentials for access.')\n",
        "        print('Your info will only be passed to %s and will not be exposed in Jupyter.' % (endpoint))\n",
        "        username = input('Username: ')\n",
        "        password = getpass('Password: ')\n",
        "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
        "    manager.add_password(None, endpoint, username, password)\n",
        "    auth = request.HTTPBasicAuthHandler(manager)\n",
        "    jar = CookieJar()\n",
        "    processor = request.HTTPCookieProcessor(jar)\n",
        "    opener = request.build_opener(auth, processor)\n",
        "    request.install_opener(opener)\n",
        "    \n",
        "setup_earthdata_login_auth()"
      ],
      "metadata": {
        "id": "Ik8qTo3IyiHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we use SWOT Simulated Level-2 KaRIn SSH from GLORYS for Science Version 1. More information on the datasets can be found at https://podaac.jpl.nasa.gov/dataset/SWOT_SIMULATED_L2_KARIN_SSH_GLORYS_SCIENCE_V1. \n",
        "\n",
        "From the Earthdata search, we identify the shortname for the dataset we are interested in and a series of filenames that we want to download. "
      ],
      "metadata": {
        "id": "OFuUKkrc8nm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ShortName = \"SWOT_SIMULATED_L2_KARIN_SSH_GLORYS_SCIENCE_V1\"\n",
        "\n",
        "remote_files = ['SWOT_L2_LR_SSH_Expert_001_001_20140412T120000_20140412T125126_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_002_20140412T125126_20140412T134253_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_003_20140412T134253_20140412T143420_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_004_20140412T143420_20140412T152546_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_005_20140412T152547_20140412T161713_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_006_20140412T161714_20140412T170840_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_007_20140412T170840_20140412T180007_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_008_20140412T180008_20140412T185134_DG10_01.nc',\n",
        " 'SWOT_L2_LR_SSH_Expert_001_009_20140412T185134_20140412T194301_DG10_01.nc']"
      ],
      "metadata": {
        "id": "cBHTyojH2L3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we download the remote files one-by-one into our Colab directory and then concatenate them into a single xarray dataset. The resulting dataset has much more \"Expert\" level information such as estimated errors calculated using the SWOT simulator. "
      ],
      "metadata": {
        "id": "pG8k-fZLkG8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files to virtual machine\n",
        "for target_file in remote_files:\n",
        "  print(target_file)\n",
        "  https_access = f\"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/{ShortName}/{target_file}\"\n",
        "  request.urlretrieve(https_access, target_file)\n",
        "\n",
        "# Load netCDF with 'xarray' after download completes\n",
        "ds1 = xr.open_mfdataset(\"SWOT_L2_LR_SSH_Expert_001_0*.nc\", combine='nested', concat_dim=\"num_lines\", decode_times=False)\n",
        "\n",
        "# Look at the dataset\n",
        "ds1"
      ],
      "metadata": {
        "id": "aSo6XSer0JE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the data on a global map. Notice that we have concatenated several passes into a single dataset. "
      ],
      "metadata": {
        "id": "emDfsFcTkcYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21, 12))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_global()\n",
        "ds1.ssha_karin.plot.pcolormesh(\n",
        " ax=ax, transform=ccrs.PlateCarree(), x=\"longitude\", y=\"latitude\", add_colorbar=False\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.gridlines()"
      ],
      "metadata": {
        "id": "UDqyV6dA5QHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's zoom in on the Bass Strait region and visualize the errors. \n",
        "\n",
        "The errors look cool, but if we do the same thing for the SSH anomaly, the result looks strange. I don't know why it looks this way. "
      ],
      "metadata": {
        "id": "5XKqXM_ekmWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lolabox = [143, 147, -42, -38] # Bass Strait\n",
        "plt.figure(figsize=(21, 12))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent(lolabox)\n",
        "ds1.simulated_error_karin.plot.pcolormesh(\n",
        " ax=ax, transform=ccrs.PlateCarree(), x=\"longitude\", y=\"latitude\", add_colorbar=True\n",
        ")\n",
        "ax.coastlines()"
      ],
      "metadata": {
        "id": "UtdoLr_e5byu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Nadir data\n",
        "\n",
        "So far we have looked at simulated 2D swath data from the KaRIn instrument on SWOT. SWOT also carries a traditional nadir (downward-looking) altimeter that measures sea surface height directly below the satellite. This is stored in a different dataset. \n",
        "\n",
        "Download the nadir data from the Earthdata server. "
      ],
      "metadata": {
        "id": "iSTxH_wok1v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ShortName = \"SWOT_SIMULATED_L2_NADIR_SSH_GLORYS_SCIENCE_V1\"\n",
        "target_file = 'SWOT_GPR_2PTP001_008_20140412_180008_20140412_185134.nc'\n",
        "\n",
        "print(target_file)\n",
        "https_access = f\"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/{ShortName}/{target_file}\"\n",
        "request.urlretrieve(https_access, target_file)"
      ],
      "metadata": {
        "id": "4jxl823o_dMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the data into an xarray dataset. Note that the netcdf files have data in two separate \"Groups\". We will merge these groups into a single xarray dataset. "
      ],
      "metadata": {
        "id": "8uYkAT48lK6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsA = xr.open_dataset(target_file,group=\"/data_01/ku\")\n",
        "dsB = xr.open_dataset(target_file,group=\"/data_01/\")\n",
        "\n",
        "ds2 = xr.Dataset.merge(dsA,dsB)\n",
        "ds2"
      ],
      "metadata": {
        "id": "hm8KfDmhWZo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising nadir data\n",
        "\n",
        "Data from the nadir instrument can be plotted against time, latitude, or longitude. Let's do this with the measured SSH and the \"true\" SSH (i.e. from the model). Switching between visualizations causes the plots to stretch or shrink in different places because of the satellite orbit. "
      ],
      "metadata": {
        "id": "ery7yN9Blbih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 16))\n",
        "plt.subplot(3,1,1)\n",
        "ds2.simulated_true_ssh.plot(x=\"time\")\n",
        "ds2.ssh.plot(x=\"time\")\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "ds2.simulated_true_ssh.plot(x=\"longitude\")\n",
        "ds2.ssh.plot(x=\"longitude\")\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "ds2.simulated_true_ssh.plot(x=\"latitude\")\n",
        "ds2.ssh.plot(x=\"latitude\")"
      ],
      "metadata": {
        "id": "rWLGg9j_Wa6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's zoom in on the Bass strait region again. We can limit our plots based on the longitude and latitude box we used for the Bass Strait region. "
      ],
      "metadata": {
        "id": "x75xNfw-l5TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 4))\n",
        "\n",
        "p1 = plt.subplot(1,2,1)\n",
        "ds2.simulated_true_ssh.plot(x=\"longitude\")\n",
        "ds2.ssh.plot(x=\"longitude\")\n",
        "p1.set_xlim(lolabox[0],lolabox[1])\n",
        "\n",
        "p2 = plt.subplot(1,2,2)\n",
        "ds2.simulated_true_ssh.plot(x=\"latitude\")\n",
        "ds2.ssh.plot(x=\"latitude\")\n",
        "p2.set_xlim(lolabox[2],lolabox[3])"
      ],
      "metadata": {
        "id": "4cUmKSohF3RG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}